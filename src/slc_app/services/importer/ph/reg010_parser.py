import os
import re
from typing import List, Tuple

import pandas as pd
import tabula.io as tabula
from sqlmodel import Session

from slc_app.models import Facture, Poste, SourceColFacture, SourceColPoste
from slc_app.services.importer.ph.base_processor import BaseProcessor


class ParserREG010(BaseProcessor):
    """Processeur spÃ©cialisÃ© pour l'extraction des donnÃ©es des PDF REG010"""

    def __init__(self):
        super().__init__()

    def _extract_data_from_pdf(self, pdf_path: str) -> pd.DataFrame | None:
        """Extraire les donnÃ©es d'un PDF REG010 de maniÃ¨re robuste"""
        try:
            self.log_info(f"Traitement du fichier: {pdf_path}")
            self.log_info(f"ðŸ”„ Extraction du PDF: {os.path.basename(pdf_path)}")

            # Extraire les tableaux du PDF avec lattice
            dfs = tabula.read_pdf(
                pdf_path,
                pages="all",
                lattice=True,
                pandas_options={"header": None},
            )

            if not dfs:
                self.log_warning(f"Aucun tableau trouvÃ© dans {pdf_path}")
                return None

            # Combiner tous les DataFrames
            combined_df = pd.concat(dfs, ignore_index=True)
            self.log_info(
                f"ðŸ“Š DonnÃ©es brutes extraites: {len(combined_df)} lignes, {combined_df.shape[1]} colonnes"
            )

            if combined_df.empty or combined_df.shape[1] < 7:
                self.log_error(
                    f"Format incorrect: {combined_df.shape[1]} colonnes (minimum 7 requis)"
                )
                return None

            return combined_df

        except Exception as e:
            self.log_error(f"Erreur dans {pdf_path}: {str(e)}")
            import traceback

            traceback.print_exc()
            return None

    def _process_extracted_data(
        self, combined_df: pd.DataFrame, pdf_path: str
    ) -> tuple[pd.DataFrame | None, pd.DataFrame | None]:
        """Traiter les donnÃ©es extraites : nettoyage, filtrage et validation"""

        # Garder seulement les 7 premiÃ¨res colonnes
        combined_df = combined_df.iloc[:, :7]
        combined_df.columns = [
            SourceColFacture.POSTE_ID,
            SourceColFacture.NUMERO_FACTURE,
            SourceColFacture.CODE_JOURNAL,
            SourceColFacture.NUMERO_COMPTE_COMPTABLE,
            SourceColFacture.MONTANT_COMPTABLE,
            SourceColFacture.LIBELLE_ECRITURE,
            SourceColFacture.REFERENCES_PARTENAIRE_FACTURE,
        ]

        # Nettoyer les donnÃ©es: supprimer les lignes complÃ¨tement vides
        combined_df = combined_df.dropna(how="all")
        self.log_info(f"ðŸ“Š AprÃ¨s suppression des lignes vides: {len(combined_df)}")

        # Ã‰TAPE 1: Filtrer par montants valides
        factures_df = self._filter_by_valid_amounts(combined_df, pdf_path)

        # ETAPE 2: convertir les montants en float
        factures_df[SourceColFacture.MONTANT_COMPTABLE] = factures_df[
            SourceColFacture.MONTANT_COMPTABLE
        ].astype(float)

        if factures_df.empty:
            self.log_warning("Aucune ligne avec montant valide trouvÃ©e")
            return None, None

        # Ã‰TAPE 3: Extension des natures
        factures_df = self._extend_natures(factures_df)
        factures_df = self._remove_duplicates(factures_df)

        # Ã‰TAPE 8: Extraire les natures uniques
        postes_uniques = (
            factures_df[[SourceColFacture.POSTE_ID]]
            .copy()
            .dropna()
            .drop_duplicates()
            .reset_index(drop=True)
        )

        # Extraire seulement le code du poste
        factures_df[SourceColFacture.POSTE_ID] = factures_df[SourceColFacture.POSTE_ID].str.extract(
            r"([A-Z][A-Z0-9]{1,5}) - "
        )[0]

        postes_uniques.rename(columns={SourceColFacture.POSTE_ID: "poste"}, inplace=True)
        self.log_info(f"ðŸ·ï¸ {len(postes_uniques)} postes uniques identifiÃ©s.")
        # Extraire le code et le label Ã  partir de la colonne 'nom' avec le regex
        df_postes = postes_uniques["poste"].str.extract(r"^([A-Z][A-Z0-9]+) - (.*)$")
        df_postes.columns = [SourceColPoste.CODE, SourceColPoste.NOM]
        # Si besoin, garder la colonne source

        self._display_final_results(factures_df)

        return factures_df, df_postes

    def _filter_by_valid_amounts(self, df: pd.DataFrame, pdf_path: str) -> pd.DataFrame:
        """Filtrer les lignes avec des montants valides"""
        self.log_info("ðŸ’° Filtrage par montants valides...")

        montant_pattern = r"^-?\d+\.\d{1,2}$"
        df[SourceColFacture.MONTANT_COMPTABLE] = (
            df[SourceColFacture.MONTANT_COMPTABLE].astype(str).str.strip()
        )

        # Log des lignes rejetÃ©es
        for idx, row in df.iterrows():
            montant = str(row[SourceColFacture.MONTANT_COMPTABLE]).strip()
            if not montant or montant == "nan" or not re.match(montant_pattern, montant):
                self.log_debug(
                    f"Ligne rejetÃ©e ({os.path.basename(pdf_path)}) - Montant invalide: '{montant}'"
                )

        # Masque pour les montants valides
        mask_montant_valide = (
            df[SourceColFacture.MONTANT_COMPTABLE].notna()
            & (df[SourceColFacture.MONTANT_COMPTABLE] != "nan")
            & (df[SourceColFacture.MONTANT_COMPTABLE] != "")
            & df[SourceColFacture.MONTANT_COMPTABLE].str.match(montant_pattern, na=False)
        )

        self.log_info(f"ðŸ“Š Lignes avant filtrage montants: {len(df)}")
        self.log_info(f"ðŸ“Š Lignes avec montants valides: {mask_montant_valide.sum()}")

        filtered_df = df[mask_montant_valide].copy()
        self.log_info(f"ðŸ“Š Lignes aprÃ¨s filtrage montants: {len(filtered_df)}")

        return filtered_df

    def _remove_duplicates(self, df: pd.DataFrame) -> pd.DataFrame:
        """Supprimer les doublons basÃ©s sur numero_facture et montant_comptable"""
        self.log_info("ðŸ”§ Suppression des doublons...")
        nb_lignes_avant = len(df)

        df = df.drop_duplicates(
            subset=[SourceColFacture.NUMERO_FACTURE, SourceColFacture.MONTANT_COMPTABLE],
            keep="first",
        )

        nb_doublons_supprimes = nb_lignes_avant - len(df)
        if nb_doublons_supprimes > 0:
            self.log_info(f"âš ï¸ {nb_doublons_supprimes} doublons supprimÃ©s")
        else:
            self.log_info("âœ… Aucun doublon dÃ©tectÃ©")

        return df

    def _extend_natures(self, df: pd.DataFrame) -> pd.DataFrame:
        """Ã‰tendre le champ nature avec forward fill"""
        self.log_info("ðŸ”§ Extension du champ nature...")

        # Remplacer les valeurs vides par NaN pour que ffill fonctionne
        df[SourceColFacture.POSTE_ID] = df[SourceColFacture.POSTE_ID].astype(str)
        df.loc[
            df[SourceColFacture.POSTE_ID].isin(["", "nan", "NaN", "None"]),
            SourceColFacture.POSTE_ID,
        ] = pd.NA

        # Forward fill pour Ã©tendre les natures
        df[SourceColFacture.POSTE_ID] = df[SourceColFacture.POSTE_ID].ffill()

        return df

    def _display_final_results(self, df: pd.DataFrame):
        """Afficher les rÃ©sultats finaux de l'extraction"""
        self.log_success(f"Extraction terminÃ©e: {len(df)} factures valides uniques")

        if not df.empty:
            natures_trouvees = df[SourceColFacture.POSTE_ID].dropna().unique()
            self.log_info(f"ðŸ·ï¸ Natures identifiÃ©es: {list(natures_trouvees)}")

            montant_total = df[SourceColFacture.MONTANT_COMPTABLE].sum()
            self.log_info(f"ðŸ’° Montant total: {montant_total:.2f}â‚¬")

            # Debug: afficher les premiÃ¨res lignes
            self.log_info("ðŸ“‹ PremiÃ¨res lignes validÃ©es:")
            for i, row in df.head(3).iterrows():
                self.log_info(
                    f"  - Nature: {row[SourceColFacture.POSTE_ID]}, Facture: {row[SourceColFacture.NUMERO_FACTURE]}, Montant: {row[SourceColFacture.MONTANT_COMPTABLE]}"
                )

    def _save_to_database(
        self, df_factures: pd.DataFrame, df_postes: pd.DataFrame, session: Session
    ) -> Tuple[List[Facture], List[Poste]]:
        """Sauvegarder les bases de rÃ©partition et tantiÃ¨mes en base de donnÃ©es"""
        if df_factures.empty or df_postes.empty:
            raise ValueError(
                "âŒ Les DataFrames factures ou postes sont vides, impossible de continuer l'import."
            )
        try:
            postes = Poste.from_df(df_postes)

            # ARCHITECTURE CENTRALISÃ‰E: Utiliser la session passÃ©e en paramÃ¨tre
            session.add_all(postes)
            session.commit()

            # Refresh chaque poste individuellement pour rÃ©cupÃ©rer les IDs
            for poste in postes:
                session.refresh(poste)
                self.log_info(f"âœ… Poste sauvegardÃ©: {poste}")

            # CrÃ©er le mapping des codes postes vers leurs IDs APRÃˆS avoir refreshÃ© tous les postes
            poste_id_map = {p.code: p.id for p in postes}
            df_factures[SourceColFacture.POSTE_ID] = df_factures[SourceColFacture.POSTE_ID].map(
                poste_id_map
            )

            # CrÃ©er et sauvegarder les factures
            factures = Facture.from_df(df_factures)
            session.add_all(factures)
            session.commit()

            # Log dÃ©taillÃ© de chaque facture crÃ©Ã©e
            for facture in factures:
                session.refresh(facture)
                self.log_info(
                    f"ðŸ“„ Facture crÃ©Ã©e - ID: {facture.id}, Num: {facture.numero_facture}, "
                    f"Poste: {facture.poste_id}, Montant: {facture.montant_comptable}â‚¬, "
                    f"Journal: {facture.code_journal}, Compte: {facture.numero_compte_comptable}, "
                    f"LibellÃ©: {facture.libelle_ecriture}, Ref: {facture.references_partenaire_facture}"
                )

            compteur_postes, compteur_bases = len(postes), len(factures)
            self.log_info(f"âœ… {compteur_postes} postes sauvegardÃ©s en base")
            self.log_info(f"âœ… {compteur_bases} factures sauvegardÃ©es en base")

            return factures, postes

        except Exception as e:
            raise ValueError(f"Erreur lors de la sauvegarde en base de donnÃ©es: {str(e)}") from e

    def process_reg010(
        self, pdf_path: str, controle_id: int, session: Session
    ) -> Tuple[List[Facture], List[Poste]]:
        """Traiter une liste de fichiers REG010"""

        self.log_info(f"ðŸ”„ Traitement de {os.path.basename(pdf_path)}")
        data = self._extract_data_from_pdf(pdf_path)
        if data is None:
            return [], []
        df_factures, df_postes = self._process_extracted_data(data, pdf_path)
        if df_factures is None or df_postes is None:
            self.log_warning(f"Aucune facture ou poste extrait de {os.path.basename(pdf_path)}")
            return [], []
        df_postes[SourceColPoste.CONTROLE_ID] = controle_id

        factures, postes = self._save_to_database(df_factures, df_postes, session)

        return factures, postes
